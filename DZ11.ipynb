{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caS4qsZqoDFx"
   },
   "source": [
    "#  Домашняя работа\n",
    "Взять boston house-prices datase (sklearn.datasets.load_boston). Возмите 7 любых регрессоров (попробовать разные алгоритмы, поподбирать параметры, вывести итоговое качество)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "fXOi6XvioDF1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.display.float_format ='{:,.5f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "6gRKI6QhoDF3",
    "outputId": "1336353f-2683-4138-9505-fb2a3f13e7a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>2.31000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>6.57500</td>\n",
       "      <td>65.20000</td>\n",
       "      <td>4.09000</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.30000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98000</td>\n",
       "      <td>24.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.07000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>6.42100</td>\n",
       "      <td>78.90000</td>\n",
       "      <td>4.96710</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.80000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.14000</td>\n",
       "      <td>21.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.07000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>7.18500</td>\n",
       "      <td>61.10000</td>\n",
       "      <td>4.96710</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.80000</td>\n",
       "      <td>392.83000</td>\n",
       "      <td>4.03000</td>\n",
       "      <td>34.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.18000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>6.99800</td>\n",
       "      <td>45.80000</td>\n",
       "      <td>6.06220</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.70000</td>\n",
       "      <td>394.63000</td>\n",
       "      <td>2.94000</td>\n",
       "      <td>33.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.18000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>7.14700</td>\n",
       "      <td>54.20000</td>\n",
       "      <td>6.06220</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.70000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>5.33000</td>\n",
       "      <td>36.20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CRIM       ZN   INDUS  CHAS  ...  PTRATIO         B   LSTAT     MEDV\n",
       "0 0.00632 18.00000 2.31000     0  ... 15.30000 396.90000 4.98000 24.00000\n",
       "1 0.02731  0.00000 7.07000     0  ... 17.80000 396.90000 9.14000 21.60000\n",
       "2 0.02729  0.00000 7.07000     0  ... 17.80000 392.83000 4.03000 34.70000\n",
       "3 0.03237  0.00000 2.18000     0  ... 18.70000 394.63000 2.94000 33.40000\n",
       "4 0.06905  0.00000 2.18000     0  ... 18.70000 396.90000 5.33000 36.20000\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "data = pd.read_csv(load_boston()['filename'], skiprows=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "XkIMg07XoDF4"
   },
   "outputs": [],
   "source": [
    "# Разделим датасет на данные с признаками X и целевой переменной y\n",
    "X = data.iloc[:, :-1].copy()\n",
    "y = data.iloc[:, -1:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "Bkh3cgBfoDF5"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "bVI4inS5oDF7"
   },
   "outputs": [],
   "source": [
    "def get_scores(models, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=63 ) \n",
    "    score_list = [] \n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train['MEDV'])\n",
    "        score_list.append((model.__class__.__name__, model.score(X_test, y_test)))\n",
    "    return score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "5C245ZQPoDF7"
   },
   "outputs": [],
   "source": [
    "kernel = DotProduct() + WhiteKernel()\n",
    "LinR = LinearRegression()\n",
    "GausR = GaussianProcessRegressor(kernel=kernel, random_state=0)\n",
    "SGDR = SGDRegressor(loss='huber', penalty='elasticnet', learning_rate='adaptive', \n",
    "                    random_state=0, max_iter=5000000)\n",
    "HuberR= HuberRegressor(max_iter=5000)\n",
    "KNR = KNeighborsRegressor()\n",
    "LinSVR  =LinearSVR(max_iter=500000, random_state=0)\n",
    "DTR = DecisionTreeRegressor(random_state=0)\n",
    "RFR = RandomForestRegressor(random_state=0)\n",
    "\n",
    "#models =[LinR, GausR, SGDR, HuberR, KNR, LinSVR, DTR, RFR]\n",
    "models =[LinR, GausR, SGDR, HuberR, KNR, LinSVR, DTR, RFR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7rGddZRoDF8",
    "outputId": "29c806cd-d72f-434d-a74d-a3128b31edc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('LinearRegression', 0.6826784431236119),\n",
       " ('GaussianProcessRegressor', 0.6942199536326683),\n",
       " ('SGDRegressor', 0.21124008886805679),\n",
       " ('HuberRegressor', 0.7205402740330831),\n",
       " ('KNeighborsRegressor', 0.559955253729226),\n",
       " ('LinearSVR', 0.6969944951130729),\n",
       " ('DecisionTreeRegressor', 0.6356309212660141),\n",
       " ('RandomForestRegressor', 0.8299281748426962)]"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1 = [] \n",
    "score1 = get_scores(models, X, y)\n",
    "score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02fF5iBKoDF-"
   },
   "source": [
    "## Выберем признаки с наибольшей корелляцией с целевой переменной\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "juE1eGx5oDF-",
    "outputId": "5439ecea-56ed-413e-f34d-57c6cfdc78a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM      -0.38830\n",
       "ZN         0.36045\n",
       "INDUS     -0.48373\n",
       "CHAS       0.17526\n",
       "NOX       -0.42732\n",
       "RM         0.69536\n",
       "AGE       -0.37695\n",
       "DIS        0.24993\n",
       "RAD       -0.38163\n",
       "TAX       -0.46854\n",
       "PTRATIO   -0.50779\n",
       "B          0.33346\n",
       "LSTAT     -0.73766\n",
       "MEDV       1.00000\n",
       "Name: MEDV, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOH_LnNloDGA",
    "outputId": "15fd2938-ce2a-4499-dc21-bba40de08cc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LinearRegression', 0.640063816814487),\n",
       " ('GaussianProcessRegressor', 0.6333764976970895),\n",
       " ('SGDRegressor', 0.634675276240357),\n",
       " ('HuberRegressor', 0.6422460997682891),\n",
       " ('KNeighborsRegressor', 0.7236057970709229),\n",
       " ('LinearSVR', 0.6349171258192166),\n",
       " ('DecisionTreeRegressor', 0.36623478199768916),\n",
       " ('RandomForestRegressor', 0.6923480931904609)]"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_1 = [] \n",
    "cols = ['LSTAT', 'RM']\n",
    "score1_1 = get_scores(models, X[cols], y)\n",
    "score1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "WSNYIzSKoDGB"
   },
   "outputs": [],
   "source": [
    "def dif(score1, score2):\n",
    "    diff = pd.DataFrame([list(zip(*score1))[1], list(zip(*score2))[1]], columns=list(zip(*score1))[0],).T\n",
    "    diff['diff'] = diff[1]-diff[0]\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "L7qvTvaGoDGC",
    "outputId": "69e48e1b-8204-4320-ba1c-343441b028af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.68268</td>\n",
       "      <td>0.64006</td>\n",
       "      <td>-0.04261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>0.69422</td>\n",
       "      <td>0.63338</td>\n",
       "      <td>-0.06084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>0.63468</td>\n",
       "      <td>0.42344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>0.72054</td>\n",
       "      <td>0.64225</td>\n",
       "      <td>-0.07829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.55996</td>\n",
       "      <td>0.72361</td>\n",
       "      <td>0.16365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>0.69699</td>\n",
       "      <td>0.63492</td>\n",
       "      <td>-0.06208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.63563</td>\n",
       "      <td>0.36623</td>\n",
       "      <td>-0.26940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.82993</td>\n",
       "      <td>0.69235</td>\n",
       "      <td>-0.13758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0       1     diff\n",
       "LinearRegression         0.68268 0.64006 -0.04261\n",
       "GaussianProcessRegressor 0.69422 0.63338 -0.06084\n",
       "SGDRegressor             0.21124 0.63468  0.42344\n",
       "HuberRegressor           0.72054 0.64225 -0.07829\n",
       "KNeighborsRegressor      0.55996 0.72361  0.16365\n",
       "LinearSVR                0.69699 0.63492 -0.06208\n",
       "DecisionTreeRegressor    0.63563 0.36623 -0.26940\n",
       "RandomForestRegressor    0.82993 0.69235 -0.13758"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif(score1, score1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l5afc65oDGC"
   },
   "source": [
    "Видим хороший рост score у SGDRegressor, у остальных падение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7SKSSmboDGD"
   },
   "source": [
    "## Применим к признакам OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8k4S9GMoDGE",
    "outputId": "fe226ee9-9904-4301-8e3d-e4aba3f1637e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM :\t 504\n",
      "ZN :\t 26\n",
      "INDUS :\t 76\n",
      "CHAS :\t 2\n",
      "NOX :\t 81\n",
      "RM :\t 446\n",
      "AGE :\t 356\n",
      "DIS :\t 412\n",
      "RAD :\t 9\n",
      "TAX :\t 66\n",
      "PTRATIO :\t 46\n",
      "B :\t 357\n",
      "LSTAT :\t 455\n"
     ]
    }
   ],
   "source": [
    "#Смотрим из каких уникальных значений состоят признаки в колонках\n",
    "for col in X.columns:\n",
    "    print(col, ':\\t', len(X[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7bgfQCNoDGF",
    "outputId": "2b6a8c5d-7ddf-4b30-841d-b7ca6fe9725e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAD :\t [ 1  2  3  5  4  8  6  7 24]\n",
      "CHAS :\t [0 1]\n",
      "ZN :\t [ 18.    0.   12.5  75.   21.   90.   85.  100.   25.   17.5  80.   28.\n",
      "  45.   60.   95.   82.5  30.   22.   20.   40.   55.   52.5  70.   34.\n",
      "  33.   35. ]\n"
     ]
    }
   ],
   "source": [
    "#Смотрим из каких уникальных значений состоят признаки в колонках\n",
    "for col in ['RAD', 'CHAS', 'ZN']:\n",
    "    print(col, ':\\t', X[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "JgilPMWzoDGF"
   },
   "outputs": [],
   "source": [
    "# функция преобразования категориальных признаков в числовые\n",
    "def get_one_hot(X, cols):\n",
    "    for col in cols:\n",
    "        dummies = pd.get_dummies(X[col], prefix=col, drop_first=False)\n",
    "        X = pd.concat([X, dummies], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "5Vax9DuUoDGG"
   },
   "outputs": [],
   "source": [
    "# Применим OneHotEncoding\n",
    "X_ohe = get_one_hot(X, ['RAD', 'ZN'])\n",
    "X_ohe.drop(['RAD', 'ZN'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6huE-wpMoDGH",
    "outputId": "aa913a6c-6892-4881-ba29-a1ab30639255"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('LinearRegression', 0.6987689564104762),\n",
       " ('GaussianProcessRegressor', 0.6988690245024365),\n",
       " ('SGDRegressor', 0.21618625979325679),\n",
       " ('HuberRegressor', 0.727071841244921),\n",
       " ('KNeighborsRegressor', 0.5622155196430565),\n",
       " ('LinearSVR', 0.7148675565391164),\n",
       " ('DecisionTreeRegressor', 0.7535842105167888),\n",
       " ('RandomForestRegressor', 0.8281457314473375)]"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = [] \n",
    "score2 = get_scores(models, X_ohe, y)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "EdLMgdMJoDGI",
    "outputId": "9c3984c8-b7c5-42d7-d5ca-5dfbd353db76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.68268</td>\n",
       "      <td>0.69877</td>\n",
       "      <td>0.01609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>0.69422</td>\n",
       "      <td>0.69887</td>\n",
       "      <td>0.00465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>0.21619</td>\n",
       "      <td>0.00495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>0.72054</td>\n",
       "      <td>0.72707</td>\n",
       "      <td>0.00653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.55996</td>\n",
       "      <td>0.56222</td>\n",
       "      <td>0.00226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>0.69699</td>\n",
       "      <td>0.71487</td>\n",
       "      <td>0.01787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.63563</td>\n",
       "      <td>0.75358</td>\n",
       "      <td>0.11795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.82993</td>\n",
       "      <td>0.82815</td>\n",
       "      <td>-0.00178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0       1     diff\n",
       "LinearRegression         0.68268 0.69877  0.01609\n",
       "GaussianProcessRegressor 0.69422 0.69887  0.00465\n",
       "SGDRegressor             0.21124 0.21619  0.00495\n",
       "HuberRegressor           0.72054 0.72707  0.00653\n",
       "KNeighborsRegressor      0.55996 0.56222  0.00226\n",
       "LinearSVR                0.69699 0.71487  0.01787\n",
       "DecisionTreeRegressor    0.63563 0.75358  0.11795\n",
       "RandomForestRegressor    0.82993 0.82815 -0.00178"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif(score1, score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSi0hdr7oDGI"
   },
   "source": [
    "Видим небольшой рост score от OneHotEncoding, кроме SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8Hw5gVfoDGJ"
   },
   "source": [
    "## Применим к признакам нормализацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxzLH6N1oDGJ",
    "outputId": "9e5496c7-54b9-4c66-ed21-372206e7ebce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LinearRegression', -9.587123583771517e+19),\n",
       " ('GaussianProcessRegressor', 0.7002705033317957),\n",
       " ('SGDRegressor', 0.5997954666236103),\n",
       " ('HuberRegressor', 0.6199263494068303),\n",
       " ('KNeighborsRegressor', 0.7154781945031135),\n",
       " ('LinearSVR', 0.5979145914962831),\n",
       " ('DecisionTreeRegressor', 0.7537100552894216),\n",
       " ('RandomForestRegressor', 0.8291220025206805)]"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "Xtrain_sc = sc.fit_transform(X_ohe)\n",
    "score3 = []\n",
    "score3 = get_scores(models, Xtrain_sc, y)\n",
    "score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "4Aly_JAloDGK",
    "outputId": "3c988d7b-cd63-4354-bcd1-a2b6f3506638"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.69877</td>\n",
       "      <td>-95,871,235,837,715,169,280.00000</td>\n",
       "      <td>-95,871,235,837,715,169,280.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>0.69887</td>\n",
       "      <td>0.70027</td>\n",
       "      <td>0.00140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>0.21619</td>\n",
       "      <td>0.59980</td>\n",
       "      <td>0.38361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>0.72707</td>\n",
       "      <td>0.61993</td>\n",
       "      <td>-0.10715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.56222</td>\n",
       "      <td>0.71548</td>\n",
       "      <td>0.15326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>0.71487</td>\n",
       "      <td>0.59791</td>\n",
       "      <td>-0.11695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.75358</td>\n",
       "      <td>0.75371</td>\n",
       "      <td>0.00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.82815</td>\n",
       "      <td>0.82912</td>\n",
       "      <td>0.00098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0  ...                              diff\n",
       "LinearRegression         0.69877  ... -95,871,235,837,715,169,280.00000\n",
       "GaussianProcessRegressor 0.69887  ...                           0.00140\n",
       "SGDRegressor             0.21619  ...                           0.38361\n",
       "HuberRegressor           0.72707  ...                          -0.10715\n",
       "KNeighborsRegressor      0.56222  ...                           0.15326\n",
       "LinearSVR                0.71487  ...                          -0.11695\n",
       "DecisionTreeRegressor    0.75358  ...                           0.00013\n",
       "RandomForestRegressor    0.82815  ...                           0.00098\n",
       "\n",
       "[8 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif(score2, score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnIInNVEoDGL"
   },
   "source": [
    "Видим неплохой рост score от нормализации у SGDRegressor и сильное падение у LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NLxmzv4oDGM"
   },
   "source": [
    "## Преобразуем имеющиеся выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "9mdgTIPioDGM",
    "outputId": "d6923dec-6bd0-48b8-e668-714f594847e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RAD_1</th>\n",
       "      <th>RAD_2</th>\n",
       "      <th>RAD_3</th>\n",
       "      <th>RAD_4</th>\n",
       "      <th>RAD_5</th>\n",
       "      <th>RAD_6</th>\n",
       "      <th>RAD_7</th>\n",
       "      <th>RAD_8</th>\n",
       "      <th>RAD_24</th>\n",
       "      <th>ZN_0.0</th>\n",
       "      <th>ZN_12.5</th>\n",
       "      <th>ZN_17.5</th>\n",
       "      <th>ZN_18.0</th>\n",
       "      <th>ZN_20.0</th>\n",
       "      <th>ZN_21.0</th>\n",
       "      <th>ZN_22.0</th>\n",
       "      <th>ZN_25.0</th>\n",
       "      <th>ZN_28.0</th>\n",
       "      <th>ZN_30.0</th>\n",
       "      <th>ZN_33.0</th>\n",
       "      <th>ZN_34.0</th>\n",
       "      <th>ZN_35.0</th>\n",
       "      <th>ZN_40.0</th>\n",
       "      <th>ZN_45.0</th>\n",
       "      <th>ZN_52.5</th>\n",
       "      <th>ZN_55.0</th>\n",
       "      <th>ZN_60.0</th>\n",
       "      <th>ZN_70.0</th>\n",
       "      <th>ZN_75.0</th>\n",
       "      <th>ZN_80.0</th>\n",
       "      <th>ZN_82.5</th>\n",
       "      <th>ZN_85.0</th>\n",
       "      <th>ZN_90.0</th>\n",
       "      <th>ZN_95.0</th>\n",
       "      <th>ZN_100.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.41978</td>\n",
       "      <td>-1.28791</td>\n",
       "      <td>-0.27260</td>\n",
       "      <td>-0.14422</td>\n",
       "      <td>0.41367</td>\n",
       "      <td>-0.12001</td>\n",
       "      <td>0.14021</td>\n",
       "      <td>-0.66661</td>\n",
       "      <td>-1.45900</td>\n",
       "      <td>0.44105</td>\n",
       "      <td>-1.07556</td>\n",
       "      <td>4.92950</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.28495</td>\n",
       "      <td>-0.52705</td>\n",
       "      <td>-0.54233</td>\n",
       "      <td>-0.23274</td>\n",
       "      <td>-0.18645</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.59409</td>\n",
       "      <td>-1.66617</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>22.47221</td>\n",
       "      <td>-0.20808</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.11844</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.17479</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.09990</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.04450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.41734</td>\n",
       "      <td>-0.59338</td>\n",
       "      <td>-0.27260</td>\n",
       "      <td>-0.74026</td>\n",
       "      <td>0.19427</td>\n",
       "      <td>0.36717</td>\n",
       "      <td>0.55716</td>\n",
       "      <td>-0.98733</td>\n",
       "      <td>-0.30309</td>\n",
       "      <td>0.44105</td>\n",
       "      <td>-0.49244</td>\n",
       "      <td>-0.20286</td>\n",
       "      <td>4.48144</td>\n",
       "      <td>-0.28495</td>\n",
       "      <td>-0.52705</td>\n",
       "      <td>-0.54233</td>\n",
       "      <td>-0.23274</td>\n",
       "      <td>-0.18645</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.59409</td>\n",
       "      <td>0.60018</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.20808</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.11844</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.17479</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.09990</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.04450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.41734</td>\n",
       "      <td>-0.59338</td>\n",
       "      <td>-0.27260</td>\n",
       "      <td>-0.74026</td>\n",
       "      <td>1.28271</td>\n",
       "      <td>-0.26581</td>\n",
       "      <td>0.55716</td>\n",
       "      <td>-0.98733</td>\n",
       "      <td>-0.30309</td>\n",
       "      <td>0.39643</td>\n",
       "      <td>-1.20873</td>\n",
       "      <td>-0.20286</td>\n",
       "      <td>4.48144</td>\n",
       "      <td>-0.28495</td>\n",
       "      <td>-0.52705</td>\n",
       "      <td>-0.54233</td>\n",
       "      <td>-0.23274</td>\n",
       "      <td>-0.18645</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.59409</td>\n",
       "      <td>0.60018</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.20808</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.11844</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.17479</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.09990</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.04450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.41675</td>\n",
       "      <td>-1.30688</td>\n",
       "      <td>-0.27260</td>\n",
       "      <td>-0.83528</td>\n",
       "      <td>1.01630</td>\n",
       "      <td>-0.80989</td>\n",
       "      <td>1.07774</td>\n",
       "      <td>-1.10612</td>\n",
       "      <td>0.11303</td>\n",
       "      <td>0.41616</td>\n",
       "      <td>-1.36152</td>\n",
       "      <td>-0.20286</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>3.50939</td>\n",
       "      <td>-0.52705</td>\n",
       "      <td>-0.54233</td>\n",
       "      <td>-0.23274</td>\n",
       "      <td>-0.18645</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.59409</td>\n",
       "      <td>0.60018</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.20808</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.11844</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.17479</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.09990</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.04450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.41248</td>\n",
       "      <td>-1.30688</td>\n",
       "      <td>-0.27260</td>\n",
       "      <td>-0.83528</td>\n",
       "      <td>1.22858</td>\n",
       "      <td>-0.51118</td>\n",
       "      <td>1.07774</td>\n",
       "      <td>-1.10612</td>\n",
       "      <td>0.11303</td>\n",
       "      <td>0.44105</td>\n",
       "      <td>-1.02650</td>\n",
       "      <td>-0.20286</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>3.50939</td>\n",
       "      <td>-0.52705</td>\n",
       "      <td>-0.54233</td>\n",
       "      <td>-0.23274</td>\n",
       "      <td>-0.18645</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.59409</td>\n",
       "      <td>0.60018</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.20808</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.11844</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.17479</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.09990</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.04450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.41323</td>\n",
       "      <td>0.11574</td>\n",
       "      <td>-0.27260</td>\n",
       "      <td>0.15812</td>\n",
       "      <td>0.43932</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>-0.62580</td>\n",
       "      <td>-0.80321</td>\n",
       "      <td>1.17647</td>\n",
       "      <td>0.38722</td>\n",
       "      <td>-0.41815</td>\n",
       "      <td>4.92950</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.28495</td>\n",
       "      <td>-0.52705</td>\n",
       "      <td>-0.54233</td>\n",
       "      <td>-0.23274</td>\n",
       "      <td>-0.18645</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.59409</td>\n",
       "      <td>0.60018</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.20808</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.11844</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.17479</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.09990</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.04450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-0.41525</td>\n",
       "      <td>0.11574</td>\n",
       "      <td>-0.27260</td>\n",
       "      <td>0.15812</td>\n",
       "      <td>-0.23455</td>\n",
       "      <td>0.28893</td>\n",
       "      <td>-0.71664</td>\n",
       "      <td>-0.80321</td>\n",
       "      <td>1.17647</td>\n",
       "      <td>0.44105</td>\n",
       "      <td>-0.50085</td>\n",
       "      <td>4.92950</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.28495</td>\n",
       "      <td>-0.52705</td>\n",
       "      <td>-0.54233</td>\n",
       "      <td>-0.23274</td>\n",
       "      <td>-0.18645</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.59409</td>\n",
       "      <td>0.60018</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.20808</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.11844</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.17479</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.09990</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.04450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>-0.41345</td>\n",
       "      <td>0.11574</td>\n",
       "      <td>-0.27260</td>\n",
       "      <td>0.15812</td>\n",
       "      <td>0.98496</td>\n",
       "      <td>0.79745</td>\n",
       "      <td>-0.77368</td>\n",
       "      <td>-0.80321</td>\n",
       "      <td>1.17647</td>\n",
       "      <td>0.44105</td>\n",
       "      <td>-0.98305</td>\n",
       "      <td>4.92950</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.28495</td>\n",
       "      <td>-0.52705</td>\n",
       "      <td>-0.54233</td>\n",
       "      <td>-0.23274</td>\n",
       "      <td>-0.18645</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.59409</td>\n",
       "      <td>0.60018</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.20808</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.11844</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.17479</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.09990</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.04450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>-0.40776</td>\n",
       "      <td>0.11574</td>\n",
       "      <td>-0.27260</td>\n",
       "      <td>0.15812</td>\n",
       "      <td>0.72567</td>\n",
       "      <td>0.73700</td>\n",
       "      <td>-0.66844</td>\n",
       "      <td>-0.80321</td>\n",
       "      <td>1.17647</td>\n",
       "      <td>0.40322</td>\n",
       "      <td>-0.86530</td>\n",
       "      <td>4.92950</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.28495</td>\n",
       "      <td>-0.52705</td>\n",
       "      <td>-0.54233</td>\n",
       "      <td>-0.23274</td>\n",
       "      <td>-0.18645</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.59409</td>\n",
       "      <td>0.60018</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.20808</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.11844</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.17479</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.09990</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.04450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>-0.41500</td>\n",
       "      <td>0.11574</td>\n",
       "      <td>-0.27260</td>\n",
       "      <td>0.15812</td>\n",
       "      <td>-0.36277</td>\n",
       "      <td>0.43473</td>\n",
       "      <td>-0.61325</td>\n",
       "      <td>-0.80321</td>\n",
       "      <td>1.17647</td>\n",
       "      <td>0.44105</td>\n",
       "      <td>-0.66906</td>\n",
       "      <td>4.92950</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.28495</td>\n",
       "      <td>-0.52705</td>\n",
       "      <td>-0.54233</td>\n",
       "      <td>-0.23274</td>\n",
       "      <td>-0.18645</td>\n",
       "      <td>-0.22314</td>\n",
       "      <td>-0.59409</td>\n",
       "      <td>0.60018</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.04450</td>\n",
       "      <td>-0.20808</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.14199</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.11844</td>\n",
       "      <td>-0.10954</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.07723</td>\n",
       "      <td>-0.17479</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.06299</td>\n",
       "      <td>-0.09990</td>\n",
       "      <td>-0.08926</td>\n",
       "      <td>-0.04450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    INDUS     CHAS      NOX  ...  ZN_85.0  ZN_90.0  ZN_95.0  ZN_100.0\n",
       "0   -0.41978 -1.28791 -0.27260 -0.14422  ... -0.06299 -0.09990 -0.08926  -0.04450\n",
       "1   -0.41734 -0.59338 -0.27260 -0.74026  ... -0.06299 -0.09990 -0.08926  -0.04450\n",
       "2   -0.41734 -0.59338 -0.27260 -0.74026  ... -0.06299 -0.09990 -0.08926  -0.04450\n",
       "3   -0.41675 -1.30688 -0.27260 -0.83528  ... -0.06299 -0.09990 -0.08926  -0.04450\n",
       "4   -0.41248 -1.30688 -0.27260 -0.83528  ... -0.06299 -0.09990 -0.08926  -0.04450\n",
       "..       ...      ...      ...      ...  ...      ...      ...      ...       ...\n",
       "501 -0.41323  0.11574 -0.27260  0.15812  ... -0.06299 -0.09990 -0.08926  -0.04450\n",
       "502 -0.41525  0.11574 -0.27260  0.15812  ... -0.06299 -0.09990 -0.08926  -0.04450\n",
       "503 -0.41345  0.11574 -0.27260  0.15812  ... -0.06299 -0.09990 -0.08926  -0.04450\n",
       "504 -0.40776  0.11574 -0.27260  0.15812  ... -0.06299 -0.09990 -0.08926  -0.04450\n",
       "505 -0.41500  0.11574 -0.27260  0.15812  ... -0.06299 -0.09990 -0.08926  -0.04450\n",
       "\n",
       "[506 rows x 46 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_sc = pd.DataFrame(Xtrain_sc, columns=X_ohe.columns)\n",
    "Xtrain_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kkqAuwuoDGN"
   },
   "source": [
    "Посмотрим на выбросы в ['LSTAT', 'B']:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Eqx_mAifoDGN",
    "outputId": "10deeef2-e8e2-42f5-d53f-efed32692c10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.545126519962255"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bp = Xtrain_sc.boxplot(['LSTAT'], vert=False, return_type='dict')\n",
    "# получаем крайнюю правую часть уса\n",
    "high_LSTAT = bp['whiskers'][1].get_xdata()[1]\n",
    "high_LSTAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "EdC_kN4toDGO"
   },
   "outputs": [],
   "source": [
    "# Заменим значения с выбросами на медиану\n",
    "\n",
    "X_ohe_lstat = Xtrain_sc.copy()\n",
    "X_ohe_lstat.loc[X_ohe_lstat[X_ohe_lstat['LSTAT'] > high_LSTAT].index, 'LSTAT'] = X_ohe_lstat['LSTAT'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "644ndTT_oDGP",
    "outputId": "8a0acfe6-a282-4590-d9ce-f7b64f2d239e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1289850584217732"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD4CAYAAAAqw8chAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQKElEQVR4nO3cXWxcd1rH8d8z4+lxajeJ7UxtE7+Mpa4gHqds1WoR7QUmVMnSRWmgWglaCREuVrhyJCok6K4rVgghRVo5QQIUtReUjbQOXMFK2wi81DZcVCvRrlpgnV1YoXXYKNREeYGEyE3th4vkHI2dM35J7Y6f5PuRrHrO/F+e8z//84t7Eo+5uwAA21uh0QUAANZGWANAAIQ1AARAWANAAIQ1AATQtBWD7tmzxyuVyqptbty4oZaWlq2YPjTWJR/rko91yRd1Xd57771L7l7Oe29LwrpSqejdd99dtc3MzIyGh4e3YvrQWJd8rEs+1iVf1HUxs7l67/EYBAACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACIKwBIADCGgACaGp0AQCwXfz0H0zq2s1b627/yL5X9b/njmevd+0o6YOvHtyK0ghrAEhdu3lLPzr+hXW33//1V5e1r7z61laUJYnHIAAQAmENAAEQ1gAQAGENAAEQ1gAQAGENAAEQ1gBCMbNGl7CqraqPsAaAAAhrAAiAsAaAAAhrAAhgzbA2s0Uze9/MPjCz75rZ01tRyJkzZzQ0NKRCoSAzW/Wrt7dXZ86c0ZkzZ9Tb25sdb21tValUkpnljtPR0ZH1GxoaUrFY1NDQkM6cObOshvT4sWPHspqam5tVKBSWtV9Ze954tfWlddc77+bmZh04cEBDQ0N6/PHHs3MoFAo6dOhQ7pjpV3Nzs44dO7ZmTeu9DsViUb29vert7d3wGJ9EvfmPHj266rXbivnXO369fVM7xmp7IW/OesdWjvH2229vuPa8Na69Z5qbm3Xo0KG7zilv363c0/X2p5mpVCot26PHjh3L7tfaNoVCQa2trXXv/7TvA8fdV/2SdL3m+0OS/mGtPk8++aSvZXp6Ovt+YmLCBwYG/MiRIy7JzcxbWlr8oYceckkuyZMk8ba2Nt+5c6fv2rXLd+7c6Y888oh3d3f75OSkHz58OGu3Z88er1arLslLpZJ3dnb6iy++6MVi0Zubm71cLvvU1JR/9NFHPjU15QMDAz46OuoDAwPZ8bGxMW9qavIjR474wMCAj4+Pe6VS8bGxMR8YGPCJiYllteeNVy6XvauryycnJ31yctK7u7u9XC7f1XdsbMwrlYqPj497V1eXDwwMuCR/9tln/erVqz4yMuKSfP/+/V4ul727u9sPHz7sxWLRW1tbvaOjw1966SVvamry0dHRujWl89ZT2+/06dPe1dXl3d3dfvr06XWP8UmsNv+JEye8XC7nXrvNqule1m1ln3TfjI2NZWOUy+Vle3VyctK7urq8XC7fte/S9ivPMx1j5X7avXu3T0xMrLv2vDV++OGHvVAo+MjIiPf39/szzzzjkvzIkSPZORUKBd+xY4fv2rXL29ravL293Xfu3Om7d+/O9vTExISXy2XfsWOHFwoFb2pqyu5BM/MkSbxQKPjo6KiPjo56oVDw1tZW7+zs9AMHDmT3b6lUWtavs7PTJfmePXu8WCy6pGyv11ObLxvR/3vf2lD7ob8Yuqv/7Vi9N5Le9XpZXO8Nzw/rL0r6m7X6bDSsq9WqT01NeZIk3tTUlAVjqVTytra27MJNTU15pVLJ3kuPubsnSeIjIyNeKpW8Uql4kiTe2tqatalWqz4+Pu6SvFKpLKslnTsdK61pfHx82fF0nPS/tbXnjVepVJa9l9a/sm/tGCdOnHBJfvjw4aydu2eBnY6ZJImPj48vGzOtt15NtePlqe2Xfl/bbz1jfBKrzT89PZ1d+1qbWdO9rNvKPul1qO2T7te8vbBy36XtV55nvTG6urq8Wq2uu/a8NU5/oEn7pPdSkiRZu87OzuzeSq9LWme6/6rValZn2n5kZMQrlUr2urOz05Mk8SRJvKurKxuvWq1m968kb2tr81Kp5F1dXZ4kiT/99NNuZtk9nO71eu7HsF7PR6TuMLP3JTVL6pZ0IK+RmX1J0pckqbOzUzMzM6sOev369azNuXPntLi4qIWFBUnS4OCgzp8/r6WlJV27dk2SdOvWLS0uLur8+fO1f5BocXFRMzMzWlhY0HPPPadTp05lfdPxFhcXde7cOQ0ODkqSzp8/v6y+dO50rLSmwcHBZcfTcdL/zszMZK/zxpubm1v2Xlq/pGV9a8cYGBiQJB09elQvvPBC1rf23NLxBwcHtbi4qLm5OZlZVm+9mtKa66ntl36fHq89/7Wu7b1abf7r169n136j53Uv8693/JV90n1T2yfdjyv3wtzcnNz9rjnzzjOv7eLioubn5zU/P5+9Xqv2vDW+deuW5ufns2tcey+l7ZaWlrI60uuS1ln774rTe/PDDz+UdHvfvv7661n/+fn57N5Nv0/rPH78uE6dOiVJunbtmpaWljQ/P6+lpSW98soreuedd7J7+I9/3K+FhYXVP5L0b+/t40o3upfy2m/FPbKesL7p7p+VJDP7WUmnzWzI0xW/w93fkPSGJD311FM+PDy86qAzMzNK2+zbt0/FYlFJkmhxcVGzs7Pq6+vThQsX1NraqitXrqhUKqlYLKqvr0+SdOHCBUlSsVjU8PCwkiTR2bNnVSqVtHfvXl28eFGlUkkLCwsqFovat2+fZmdnJUl9fX2qrW96elpJkmRjpTXNzs4uOz49PZ3Vum/fPg0PD2ev88br7u5e9t709LT6+vrU0tKyrG/tGCdPnpQkvfnmm9kckvTyyy9ntadrNTs7qyeeeEL9/f1qaWnJ6n3sscdya6odL09tHen36fHa81/r2t6r1eZvbW3Nrv1Gz+te5l/v+Cv7pPumtk+6l1fuhf7+fl28ePGuOfPOs7+/P3eMRx99VB0dHZK0rtrz1rhUKqm9vT27xum9lCRJ1u7SpUu6fPmy9u7dm12XtE5JamlpkSTduHFDFy5cUHt7uy5fvqyzZ8+qr69PN2/e1OXLl9Xe3q6rV69Kktra2tTc3JzdA+n9e+vWLe3atUvXr19XR0eHrly5opMnT8rMsnv4t3vm9JUkqfvZ07X5shGVV9/aWL+vL79O6R8QW3KP1PuRu+an1+srXn8o6dHV+vDMmmfW94Jn1jyz5pn15j2z/ilJlyQVV+uz0bB2v72JqtWqm1kW0PW+enp6ss3R09OTHW9pack2SN447e3tWb9qteqFQsGr1eqy8Kw9Pjo6mtWUJImb2bL2K2vPG6+2vrTueuddO8f+/fuzczAzP3jwYO6YtX+Y1W7eejWtpbZfT0+P9/T0bHiMT6Le/JVKZdVrtxXzr3f8evumdozV9kLenPWOrRzjtdde23DteWtce88kSeIHDx6865zy9t3KPV1vf+YF7OjoaHa/1rZJf1hbLQNWC2r3BzesFyW9f+frA0lfWKvPvYQ1bmNd8rEu+R7EdVlPGN6PYb3mM2t3L67VBgCwtfgNRgAIgLAGgAAIawAIgLAGEIov/xWPbWer6iOsASAAwhoAAiCsASAAwhoAAiCsASAAwhoAAljPR6QCwANj1c/IXuGRfcvb79pR2oqSJBHWAJCp9/nY9W20/b3jMQgABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABEBYA0AAhDUABGDuvvmDmv23pLk1mu2RdGnTJ4+PdcnHuuRjXfJFXZd+dy/nvbElYb0eZvauuz/VkMm3MdYlH+uSj3XJdz+uC49BACAAwhoAAmhkWL/RwLm3M9YlH+uSj3XJd9+tS8OeWQMA1o/HIAAQAGENAAFsi7A2s98xMzezPY2uZTswsz80s382s/fNbNLMfqLRNW0HZvY1M/v+nbX5azPb3eiatgMz+6KZfc/MlszsvvrnahtlZp83sx+Y2Q/N7NVG17OZGh7WZtYr6aCk842uZRv5mrs/7u6flfQtSb/f6IK2iW9LGnL3xyX9m6QvN7ie7eJfJf2KpH9sdCGNZGZFSX8m6RclDUr6NTMbbGxVm6fhYS3ppKTflcTfdN7h7v9T87JFrI0kyd0n3f3jOy+/I6mnkfVsF+5+zt1/0Og6toHPSfqhu/+Hu38k6S8lPd/gmjZNUyMnN7PnJV1w9w/MrJGlbDtm9keSfl3SNUk/3+BytqPflPRXjS4C28peSf9Z8/rHkn6mQbVsui0PazP7e0ldOW+NSfqKbj8CeeCsti7u/k13H5M0ZmZfljQq6aufaoENsta63GkzJuljSd/4NGtrpPWsC+5vWx7W7v5s3nEz2y9pQFL6U3WPpO+a2efc/b+2uq5Gq7cuOb4h6awekLBea13M7Dck/ZKkX/AH6JcENrBfHmQXJPXWvO65c+y+0LDHIO7+L5IeTV+b2Y8kPeXuET8pa1OZ2Wfc/d/vvHxe0vcbWc92YWaf1+2/3/g5d/+/RteDbeefJH3GzAZ0O6R/VdKLjS1p8zT0mTXqOm5mPylpSbc/ava3GlzPdvGnkhJJ377zf2PfcfcHfm3M7Jcl/YmksqS3zOx9dz/U4LI+de7+sZmNSvo7SUVJf+7u32twWZuGXzcHgAC2wz/dAwCsgbAGgAAIawAIgLAGgAAIawAIgLAGgAAIawAI4P8B77r3B4OV2DAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bp = X_ohe_lstat.boxplot(['B'], vert=False, return_type='dict')\n",
    "# получаем крайнюю левую часть уса\n",
    "low_B = bp['whiskers'][0].get_xdata()[1]\n",
    "low_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "GwtG8q2NoDGQ"
   },
   "outputs": [],
   "source": [
    "X_ohe_ls_b = X_ohe_lstat.copy()\n",
    "X_ohe_ls_b.loc[X_ohe_ls_b[X_ohe_ls_b['B'] < low_B].index, 'B'] = X_ohe_ls_b['B'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bx8s2iOJoDGQ",
    "outputId": "edd3c6b2-d65f-4de2-afc9-a2d36539f409"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LinearRegression', 0.7009283736912069),\n",
       " ('GaussianProcessRegressor', 0.7013170319722234),\n",
       " ('SGDRegressor', 0.6113550003705279),\n",
       " ('HuberRegressor', 0.6173623115042455),\n",
       " ('KNeighborsRegressor', 0.7019220080004199),\n",
       " ('LinearSVR', 0.6102908707676656),\n",
       " ('DecisionTreeRegressor', 0.6688609760420186),\n",
       " ('RandomForestRegressor', 0.8064782284100315)]"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score4 = []\n",
    "score4 = get_scores(models, X_ohe_ls_b, y)\n",
    "score4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "hRMH7f_AoDGR",
    "outputId": "8973c7a9-266f-4ead-c29e-614269504c11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>-95,871,235,837,715,169,280.00000</td>\n",
       "      <td>0.70093</td>\n",
       "      <td>95,871,235,837,715,169,280.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>0.70027</td>\n",
       "      <td>0.70132</td>\n",
       "      <td>0.00105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>0.59980</td>\n",
       "      <td>0.61136</td>\n",
       "      <td>0.01156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>0.61993</td>\n",
       "      <td>0.61736</td>\n",
       "      <td>-0.00256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.71548</td>\n",
       "      <td>0.70192</td>\n",
       "      <td>-0.01356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>0.59791</td>\n",
       "      <td>0.61029</td>\n",
       "      <td>0.01238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.75371</td>\n",
       "      <td>0.66886</td>\n",
       "      <td>-0.08485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.82912</td>\n",
       "      <td>0.80648</td>\n",
       "      <td>-0.02264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0  ...                             diff\n",
       "LinearRegression         -95,871,235,837,715,169,280.00000  ... 95,871,235,837,715,169,280.00000\n",
       "GaussianProcessRegressor                           0.70027  ...                          0.00105\n",
       "SGDRegressor                                       0.59980  ...                          0.01156\n",
       "HuberRegressor                                     0.61993  ...                         -0.00256\n",
       "KNeighborsRegressor                                0.71548  ...                         -0.01356\n",
       "LinearSVR                                          0.59791  ...                          0.01238\n",
       "DecisionTreeRegressor                              0.75371  ...                         -0.08485\n",
       "RandomForestRegressor                              0.82912  ...                         -0.02264\n",
       "\n",
       "[8 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif(score3, score4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvoHBgO6oDGS"
   },
   "source": [
    "Благодаря работе с выбросами LinearRegression снова увеличила score,  у остальных моделей незначительные изменения в разные стороны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrxZjluQoDGS"
   },
   "source": [
    "## Посмотрим на score у моделей при разных гиперпараметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LwSXp1DhoDGT"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j94SJvc_oDGT",
    "outputId": "234b3396-1e1a-4eb4-a97e-bac00dda8738",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'poisson'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=63 ) \n",
    "models=[\n",
    "      {'name':'LinR',\"model\":LinearRegression(), 'params':{'fit_intercept': 'True'}},  \n",
    "      \n",
    "      {'name':'GausR',\"model\": GaussianProcessRegressor()  , \n",
    "           'params':{'kernel':[DotProduct(), WhiteKernel(), DotProduct() + WhiteKernel()], \n",
    "                 'alpha':[0.1, 0.5, 1], 'random_state':[0]}},\n",
    "      \n",
    "      {'name':'SGDR',\"model\": SGDRegressor(), \n",
    "           'params':{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], \n",
    "            'penalty':['l1', 'l2', 'elasticnet'], 'learning_rate':['adaptive'], \n",
    "            'random_state':[0], 'max_iter':[5000000]}},\n",
    "      \n",
    "      {'name':'HuberR',\"model\": HuberRegressor(), \n",
    "            'params':{'max_iter':[5000], 'alpha':[0.0001, 0.001, 0.01, 1], 'epsilon':[1.2, 1.5, 1.7]}},\n",
    "      \n",
    "      {'name':'KNR',\"model\": KNeighborsRegressor(), \n",
    "           'params':{'n_neighbors':[2, 3, 4, 5], 'weights':['uniform', 'distance']}},\n",
    "      \n",
    "      {'name':'LinSVR',\"model\": LinearSVR(), \n",
    "           'params':{'loss':['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                     'C':[0.1,0.2,0.3,0.5,0.7,1], 'max_iter':[50000], 'random_state':[0]}},\n",
    "      \n",
    "      {'name':'DTR',\"model\": DecisionTreeRegressor(), \n",
    "           'params':{'max_depth':[3,5,7,9,11],'criterion':['mse', 'friedman_mse', 'mae', 'poisson'],\n",
    "            'random_state':[0]}},\n",
    "      \n",
    "      {'name':'RFR',\"model\": RandomForestRegressor(), \n",
    "           'params':{'criterion':['mse', 'mae'], 'max_depth':[3,5,7,9,11], 'random_state':[0]}}\n",
    "\n",
    "]\n",
    "\n",
    "res=[]\n",
    "for v in  models:\n",
    "    res.append((v['name'], RandomizedSearchCV(v['model'], v['params'], cv=10).fit(X_train, y_train['MEDV'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e4QCCa4oDGV",
    "outputId": "22a232a5-4c1d-4c5f-a7fe-f02455209924"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LinR', RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                     estimator=LinearRegression(copy_X=True, fit_intercept=True,\n",
       "                                                n_jobs=None, normalize=False),\n",
       "                     iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                     param_distributions={'fit_intercept': 'True'},\n",
       "                     pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                     return_train_score=False, scoring=None, verbose=0)),\n",
       " ('GausR', RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                     estimator=GaussianProcessRegressor(alpha=1e-10,\n",
       "                                                        copy_X_train=True,\n",
       "                                                        kernel=None,\n",
       "                                                        n_restarts_optimizer=0,\n",
       "                                                        normalize_y=False,\n",
       "                                                        optimizer='fmin_l_bfgs_b',\n",
       "                                                        random_state=None),\n",
       "                     iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                     param_distributions={'alpha': [0.1, 0.5, 1],\n",
       "                                          'kernel': [DotProduct(sigma_0=1),\n",
       "                                                     WhiteKernel(noise_level=1),\n",
       "                                                     DotProduct(sigma_0=1) + WhiteKernel(noise_level=1)],\n",
       "                                          'random_state': [0]},\n",
       "                     pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                     return_train_score=False, scoring=None, verbose=0)),\n",
       " ('SGDR', RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                     estimator=SGDRegressor(alpha=0.0001, average=False,\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.01, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='invscaling',\n",
       "                                            loss='squared_loss', max_iter=1000,\n",
       "                                            n_iter_no_change=5, penalty='l2',\n",
       "                                            power_t=0.25, random_state=None,\n",
       "                                            shuffle=True, tol=0.001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            wa...\n",
       "                     iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                     param_distributions={'learning_rate': ['adaptive'],\n",
       "                                          'loss': ['squared_loss', 'huber',\n",
       "                                                   'epsilon_insensitive',\n",
       "                                                   'squared_epsilon_insensitive'],\n",
       "                                          'max_iter': [5000000],\n",
       "                                          'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                                          'random_state': [0]},\n",
       "                     pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                     return_train_score=False, scoring=None, verbose=0)),\n",
       " ('HuberR', RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                     estimator=HuberRegressor(alpha=0.0001, epsilon=1.35,\n",
       "                                              fit_intercept=True, max_iter=100,\n",
       "                                              tol=1e-05, warm_start=False),\n",
       "                     iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                     param_distributions={'alpha': [0.0001, 0.001, 0.01, 1],\n",
       "                                          'epsilon': [1.2, 1.5, 1.7],\n",
       "                                          'max_iter': [5000]},\n",
       "                     pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                     return_train_score=False, scoring=None, verbose=0)),\n",
       " ('KNR', RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                     estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                                   metric='minkowski',\n",
       "                                                   metric_params=None,\n",
       "                                                   n_jobs=None, n_neighbors=5,\n",
       "                                                   p=2, weights='uniform'),\n",
       "                     iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                     param_distributions={'n_neighbors': [2, 3, 4, 5],\n",
       "                                          'weights': ['uniform', 'distance']},\n",
       "                     pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                     return_train_score=False, scoring=None, verbose=0)),\n",
       " ('LinSVR', RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                     estimator=LinearSVR(C=1.0, dual=True, epsilon=0.0,\n",
       "                                         fit_intercept=True,\n",
       "                                         intercept_scaling=1.0,\n",
       "                                         loss='epsilon_insensitive',\n",
       "                                         max_iter=1000, random_state=None,\n",
       "                                         tol=0.0001, verbose=0),\n",
       "                     iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                     param_distributions={'C': [0.1, 0.2, 0.3, 0.5, 0.7, 1],\n",
       "                                          'loss': ['epsilon_insensitive',\n",
       "                                                   'squared_epsilon_insensitive'],\n",
       "                                          'max_iter': [50000],\n",
       "                                          'random_state': [0]},\n",
       "                     pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                     return_train_score=False, scoring=None, verbose=0)),\n",
       " ('DTR', RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                     estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                     criterion='mse',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort='deprecated',\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best'),\n",
       "                     iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                     param_distributions={'criterion': ['mse', 'friedman_mse',\n",
       "                                                        'mae', 'poisson'],\n",
       "                                          'max_depth': [3, 5, 7, 9, 11],\n",
       "                                          'random_state': [0]},\n",
       "                     pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                     return_train_score=False, scoring=None, verbose=0)),\n",
       " ('RFR', RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                     estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     criterion='mse',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     max_samples=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=None, oob_score=False,\n",
       "                                                     random_state=None, verbose=0,\n",
       "                                                     warm_start=False),\n",
       "                     iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                     param_distributions={'criterion': ['mse', 'mae'],\n",
       "                                          'max_depth': [3, 5, 7, 9, 11],\n",
       "                                          'random_state': [0]},\n",
       "                     pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                     return_train_score=False, scoring=None, verbose=0))]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cfs0gdjnoDGX",
    "outputId": "db54261c-0e09-4c6f-9489-3d0bb8403608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinR 0.7094008670949444 {'fit_intercept': 'T'}\n",
      "GausR 0.7094025985214327 {'random_state': 0, 'kernel': DotProduct(sigma_0=1), 'alpha': 0.1}\n",
      "SGDR 0.3377958379675685 {'random_state': 0, 'penalty': 'l1', 'max_iter': 5000000, 'loss': 'huber', 'learning_rate': 'adaptive'}\n",
      "HuberR 0.7028409199733436 {'max_iter': 5000, 'epsilon': 1.7, 'alpha': 0.001}\n",
      "KNR 0.48406027731422413 {'weights': 'distance', 'n_neighbors': 5}\n",
      "LinSVR 0.6777707628894436 {'random_state': 0, 'max_iter': 50000, 'loss': 'squared_epsilon_insensitive', 'C': 0.1}\n",
      "DTR 0.760900289443625 {'random_state': 0, 'max_depth': 7, 'criterion': 'mse'}\n",
      "RFR 0.8401912925167299 {'random_state': 0, 'max_depth': 9, 'criterion': 'mse'}\n"
     ]
    }
   ],
   "source": [
    "for r in res:\n",
    "    print(r[0], r[1].best_score_, r[1].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O00XLgbBthqb",
    "outputId": "33ed5cd0-0c6f-4d3f-95c1-83e8ec1dcf54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6826784431236119"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinR = LinearRegression(*res[0][1].best_params_)\n",
    "LinR.fit(X_train, y_train['MEDV'])\n",
    "LinR.score(X_test, y_test['MEDV'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kp9nBdc8v0Q8",
    "outputId": "1eba5e2b-3770-4fb7-96a8-4ff9d8688df6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('LinR', 0.6826784431236119),\n",
       " ('GausR', 0.6838225741583557),\n",
       " ('SGDR', 0.27979865800141934),\n",
       " ('HuberR', 0.7235050364275157),\n",
       " ('KNR', 0.5887005603752999),\n",
       " ('LinSVR', 0.6370005776194948),\n",
       " ('DTR', 0.6656764673273299),\n",
       " ('RFR', 0.8260917384957642)]"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим score на тестовой выборке\n",
    "scores5 = []\n",
    "for v, r in zip(models, res):\n",
    "  qq = v['model'].set_params(**r[1].best_params_)\n",
    "  qq.fit(X_train,y_train['MEDV'])\n",
    "  scores5.append((r[0], qq.score(X_test, y_test)))\n",
    "scores5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "IvtpF233zUKB",
    "outputId": "3f8a0966-d24c-4cbb-edbf-39a369b52a25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.70093</td>\n",
       "      <td>0.68268</td>\n",
       "      <td>-0.01825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>0.70132</td>\n",
       "      <td>0.68382</td>\n",
       "      <td>-0.01749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>0.61136</td>\n",
       "      <td>0.27980</td>\n",
       "      <td>-0.33156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>0.61736</td>\n",
       "      <td>0.72351</td>\n",
       "      <td>0.10614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.70192</td>\n",
       "      <td>0.58870</td>\n",
       "      <td>-0.11322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>0.61029</td>\n",
       "      <td>0.63700</td>\n",
       "      <td>0.02671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.66886</td>\n",
       "      <td>0.66568</td>\n",
       "      <td>-0.00318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.80648</td>\n",
       "      <td>0.82609</td>\n",
       "      <td>0.01961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0       1     diff\n",
       "LinearRegression         0.70093 0.68268 -0.01825\n",
       "GaussianProcessRegressor 0.70132 0.68382 -0.01749\n",
       "SGDRegressor             0.61136 0.27980 -0.33156\n",
       "HuberRegressor           0.61736 0.72351  0.10614\n",
       "KNeighborsRegressor      0.70192 0.58870 -0.11322\n",
       "LinearSVR                0.61029 0.63700  0.02671\n",
       "DecisionTreeRegressor    0.66886 0.66568 -0.00318\n",
       "RandomForestRegressor    0.80648 0.82609  0.01961"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif(score4, scores5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH5lY3-azkA9"
   },
   "source": [
    "Параметры незначительно изменились в разные стороны у моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6rWMXj9zs_1"
   },
   "source": [
    "## В зависимости от того проводятся ли преобразования у признаков либо меняются гиперпараметры, модели ведут себя по разному: для одних моделей score может увеличиваться, для каких-то уменьшаться.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DZ11.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "272px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
