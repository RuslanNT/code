{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 50 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  100 non-null    float64\n",
      " 1   sepal width (cm)   100 non-null    float64\n",
      " 2   petal length (cm)  100 non-null    float64\n",
      " 3   petal width (cm)   100 non-null    float64\n",
      " 4   target             100 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 4.7 KB\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_iris().data\n",
    "target = datasets.load_iris().target\n",
    "c = np.column_stack([data, target])\n",
    "\n",
    "df = pd.DataFrame(c, columns=['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'target'])\n",
    "df1 = df.query(\"target > 0\")\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.delete(df1.values, 4, 1)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(df1['target'])\n",
    "Y = pd.Series(data = le.transform(df1['target']))\n",
    "Y = Y.to_numpy()\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.74644375, -0.37828438, -0.96220013, -1.00089226],\n",
       "       [-1.05963694, -1.83322428, -1.08662256, -1.00089226],\n",
       "       [ 1.44590853,  0.20369159,  1.27740362,  0.79175059],\n",
       "       [-0.74644375, -0.08729639, -0.8377777 , -1.00089226],\n",
       "       [-1.21623353,  0.20369159, -0.46451041, -0.55273155]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, Y, train_size=0.3, random_state=63, stratify=Y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "SC = StandardScaler()\n",
    "x_t = SC.fit_transform(Xtrain)\n",
    "x_t[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    return 1.0 / (1 + np.exp(-a))\n",
    "\n",
    "def cost(x, y, theta, m):\n",
    "    h = sigmoid(np.matmul(x, theta))\n",
    "    cost2 = (-np.log(h[y == 1]).sum()      -  np.log(1 - h[y == 0]).sum()) /m\n",
    "    #cost = (np.matmul(-y.T, np.log(h))  -  np.matmul((1 - y.T), np.log(1 - h))) /m\n",
    "    return cost2\n",
    "\n",
    "def gradient(theta, x, y, m):\n",
    "    h = sigmoid(np.matmul(x, theta))\n",
    "    grad = np.matmul(x.T, (h - y)) / m\n",
    "    return grad\n",
    "\n",
    "def gradient_Descent(theta, alpha, grad):\n",
    "    theta = theta - alpha * grad\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta = np.array([0, 0, 0, 0, 0])\n",
    "#ones = np.ones(X.shape[0])\n",
    "ones = np.array([[1] * x_t.shape[0]]).T\n",
    "Xd = np.hstack([ones, x_t])\n",
    "\n",
    "m = x_t.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество шагов: 37128\n",
      "cost: 0.004136405426724645 Theta: [ 1.19071738  0.69232861  1.2452645   4.28365669 14.06206126]\n",
      "Доля правильно предсказанных классов: 0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Градиентный спуск\n",
    "Theta = np.array([0, 0, 0, 0, 0])\n",
    "cost_prev = np.inf\n",
    "learning_rate = 0.1\n",
    "tol = 1e-7\n",
    "max_iter = 1e7\n",
    "\n",
    "for i in range(int(max_iter)):    \n",
    "    grad = gradient(Theta, Xd, ytrain, m)\n",
    "    Theta = Theta - learning_rate * grad\n",
    "    loss = cost(Xd, ytrain, Theta, m)\n",
    "    if cost_prev - loss < tol:\n",
    "        break\n",
    "    cost_prev = loss\n",
    "\n",
    "print('Количество шагов:', i)\n",
    "print('cost:', cost(Xd, ytrain, Theta, m), 'Theta:', Theta)\n",
    "\n",
    "Xtest_scaled = SC.transform(Xtest)\n",
    "Xtest_scaled = np.c_[np.ones(Xtest_scaled.shape[0]), Xtest_scaled]\n",
    "y_pred = sigmoid(np.matmul(Xtest_scaled, Theta))\n",
    "print(\"Доля правильно предсказанных классов:\", np.sum(ytest == np.where(y_pred >= 0.5, 1, 0))/len(ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск методом Нестерова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество шагов: 506\n",
      "cost: 0.00010631988593405196 Theta: [ 2.32875895  4.99154728  3.96441557 17.95671876 29.4497952 ]\n",
      "Доля правильно предсказанных классов: 0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Градиентный спуск методом Нестерова\n",
    "\n",
    "Theta = np.array([0, 0, 0, 0, 0])\n",
    "cost_prev = np.inf\n",
    "v = 0 # скорость\n",
    "mu = 0.99 # коэффициент трения (моментум) [0.5, 0.9, 0.95, 0.99]\n",
    "learning_rate = 0.1\n",
    "tol = 1e-7\n",
    "max_iter = 1e7\n",
    "\n",
    "for i in range(int(max_iter)):    \n",
    "    grad = gradient(Theta, Xd, ytrain, m)\n",
    "    prev_v = v\n",
    "    v = rho * v - learning_rate * grad\n",
    "    Theta = Theta - mu * prev_v + (1 + mu) * v\n",
    "    loss = cost(Xd, ytrain, Theta, m)\n",
    "    if cost_prev - loss < tol:\n",
    "        break\n",
    "    cost_prev = loss\n",
    "\n",
    "print('Количество шагов:', i)\n",
    "print('cost:', cost(Xd, ytrain, Theta, m), 'Theta:', Theta)\n",
    "\n",
    "Xtest_scaled = SC.transform(Xtest)\n",
    "Xtest_scaled = np.c_[np.ones(Xtest_scaled.shape[0]), Xtest_scaled]\n",
    "y_pred = sigmoid(np.matmul(Xtest_scaled, Theta))\n",
    "print(\"Доля правильно предсказанных классов:\", np.sum(ytest == np.where(y_pred >= 0.5, 1, 0))/len(ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск методом RMSProp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество шагов: 499\n",
      "cost: 4.954668021783887e-06 Theta: [ 3.61002725  8.65258334  8.5650289  24.63253094 37.93860235]\n",
      "Доля правильно предсказанных классов: 0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Градиентный спуск методом RMSProp\n",
    "            \n",
    "Theta = np.array([0, 0, 0, 0, 0])\n",
    "#Theta = np.random.rand(Xd.shape[1])\n",
    "cost_prev = np.inf\n",
    "grad_squared = 0\n",
    "decay_rate = 0.9 # уровень угасания [0.9, 0.99, 0.999]\n",
    "learning_rate = 0.1\n",
    "tol = 1e-7\n",
    "max_iter = 1e7\n",
    "\n",
    "for i in range(int(max_iter)):    \n",
    "    grad = gradient(Theta, Xd, ytrain, m)\n",
    "    grad_squared  = decay_rate * grad_squared + (1 - decay_rate) * grad * grad\n",
    "    Theta = Theta - learning_rate * grad / (np.sqrt(grad_squared) + 1e-7)\n",
    "    loss = cost(Xd, ytrain, Theta, m)\n",
    "    if cost_prev - loss < tol:\n",
    "        break\n",
    "    cost_prev = loss\n",
    "\n",
    "print('Количество шагов:', i)\n",
    "print('cost:', cost(Xd, ytrain, Theta, m), 'Theta:', Theta)\n",
    "\n",
    "Xtest_scaled = SC.transform(Xtest)\n",
    "Xtest_scaled = np.c_[np.ones(Xtest_scaled.shape[0]), Xtest_scaled]\n",
    "y_pred = sigmoid(np.matmul(Xtest_scaled, Theta))\n",
    "print(\"Доля правильно предсказанных классов:\", np.sum(ytest == np.where(y_pred >= 0.5, 1, 0))/len(ytest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
